[T1]
csv_file = /eyes_config/allT1.csv
#path_to_search = /images
#filename_contains = _t1w
#filename_not_contains = _seg
#filename_removefromid = 
spatial_window_size = (48, 48, 48)
# define patch size, may need to make smaller
interp_order = 0
pixdim = (1.0, 1.0, 1.0)
axcodes = (R, A, S)
#interp_order = 3

#[T2]
# csv_file = ./allT2.csv
#path_to_search = /images
#filename_contains = _t2w
#filename_not_contains = _seg
#spatial_window_size = (96, 96, 96)
#pixdim = (1.0, 1.0, 1.0)
#axcodes=(R, A, S)
#interp_order = 3

[eye_mask]
csv_file = ./allMask.csv
#path_to_search = ./images
#filename_contains = _seg
#filename_not_contains = _t2w
spatial_window_size = (48, 48, 48)
pixdim = (1.0, 1.0, 1.0)
axcodes = (R, A, S)
interp_order = 0

#[parcellation]
#csv_file = ./allSeg.csv
#path_to_search = /images
#filename_contains = _seg
#filename_not_contains = _t2w
#spatial_window_size = (96, 96, 96)
#pixdim = (1.0, 1.0, 1.0)
#axcodes = (R, A, S)
#interp_order = 0

############################## system configuration sections
[SYSTEM]
cuda_devices = ""
num_threads = 12 
# num CPU threads for processing
num_gpus = 1
model_dir = ./eyes_outputs 
# any directory, base of output
dataset_split_file = ./dataSplit.csv

[NETWORK]
name = highres3dnet
batch_size = 1
queue_length = 5
activation_function = relu
volume_padding_size = 10
decay = 0
reg_type = L2

# volume level preprocessing
norm_type = percentile
whitening = True
normalisation = True
normalise_foreground_only=True
foreground_type = mean_plus
# histogram normalisation
histogram_ref_file = ./databrain_std_hist_models_otsu.txt
cutoff = (0.001, 0.999)
multimod_foreground_type = and

window_sampling = uniform

[TRAINING]
dataset_split_file = ./dataSplit.csv
validation_every_n = 100
sample_per_volume = 32
rotation_angle = (-10.0, 10.0) 
# built-in augmentation
scaling_percentage = (-10.0, 10.0)
# can lower these to +-.1
lr = 0.0001
loss_type = Dice
starting_iter = 0 
# 'restart' value for training -- update after killing
save_every_n = 100 
# checkpoint every 100
#max_iter = 50
max_iter = 100000
max_checkpoints = 20000

[INFERENCE]
border = 2
inference_iter = 35000 
# start value
#inference_iter = 50
save_seg_dir = /eyes_outputs/outputs
output_postfix = _net_seg 
# name with input variables
output_interp_order = 0
spatial_window_size = (48, 48, 48)

############################ custom configuration sections
[SEGMENTATION]
image = T1
label = eye_mask
output_prob = False
num_classes = 4
label_normalisation = False
